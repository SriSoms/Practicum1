{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicum I\n",
    "\n",
    "# Rating Prediction with Online Learning Model\n",
    "\n",
    "### Sri Sowmya Madabhushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (1,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DaveZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>Good!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-12T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>Fantastic Tablet for kids</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>explore42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "        asins   brand                                         categories  \\\n",
       "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "3  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "4  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "                                                keys manufacturer  \\\n",
       "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "3  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "4  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "\n",
       "               reviews.date     reviews.dateAdded  \\\n",
       "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "3  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "4  2017-01-12T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "\n",
       "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
       "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "3  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "4  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "\n",
       "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
       "0        NaN                 0.0             5.0   \n",
       "1        NaN                 0.0             5.0   \n",
       "2        NaN                 0.0             5.0   \n",
       "3        NaN                 0.0             4.0   \n",
       "4        NaN                 0.0             5.0   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "3  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "4  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  This product so far has not disappointed. My c...   \n",
       "1  great for beginner or experienced person. Boug...   \n",
       "2  Inexpensive tablet for him to use and learn on...   \n",
       "3  I've had my Fire HD 8 two weeks now and I love...   \n",
       "4  I bought this for my grand daughter when she c...   \n",
       "\n",
       "                             reviews.title reviews.userCity  \\\n",
       "0                                   Kindle              NaN   \n",
       "1                                very fast              NaN   \n",
       "2  Beginner tablet for our 9 year old son.              NaN   \n",
       "3                                  Good!!!              NaN   \n",
       "4                Fantastic Tablet for kids              NaN   \n",
       "\n",
       "   reviews.userProvince  reviews.username  \n",
       "0                   NaN           Adapter  \n",
       "1                   NaN            truman  \n",
       "2                   NaN             DaveZ  \n",
       "3                   NaN            Shacks  \n",
       "4                   NaN         explore42  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "reviews_df = pd.read_csv('amazon_reviews.csv')\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                             Review\n",
       "0     5.0  This product so far has not disappointed. My c...\n",
       "1     5.0  great for beginner or experienced person. Boug...\n",
       "2     5.0  Inexpensive tablet for him to use and learn on...\n",
       "3     4.0  I've had my Fire HD 8 two weeks now and I love...\n",
       "4     5.0  I bought this for my grand daughter when she c..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the rating and reviews columns\n",
    "reviews_df = reviews_df[['reviews.rating','reviews.text']]\n",
    "reviews_df.columns=['Rating','Review']\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    33\n",
       "Review     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing steps- checking if any nulls\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating    0\n",
       "Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the null rows as very less number of nulls\n",
    "reviews_df.dropna(inplace=True)\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping each rating to number\n",
    "ratingmap = {5:5,4:4,3:3,2:2,1:1}\n",
    "reviews_df['Sentiment'] = reviews_df['Rating'].map(ratingmap)\n",
    "reviews_df.drop(['Rating'], axis=1, inplace=True) \n",
    "reviews_df.dropna(subset=['Sentiment'], inplace=True) \n",
    "reviews_df['Sentiment']=reviews_df['Sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  This product so far has not disappointed. My c...          5\n",
       "1  great for beginner or experienced person. Boug...          5\n",
       "2  Inexpensive tablet for him to use and learn on...          5\n",
       "3  I've had my Fire HD 8 two weeks now and I love...          4\n",
       "4  I bought this for my grand daughter when she c...          5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the reviews data\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    23774\n",
       "4     8541\n",
       "3     1499\n",
       "1      410\n",
       "2      402\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows/data for each review type\n",
    "reviews_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(np.array(['5', '4', '3', '2', '1']), np.array([23774,8541,1499,410,402]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34626, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape to see number of columns and rows\n",
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    1500\n",
      "4    1500\n",
      "3    1499\n",
      "1     410\n",
      "2     402\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5311, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_5 = reviews_df[reviews_df.Sentiment==5]\n",
    "df_4 = reviews_df[reviews_df.Sentiment==4]\n",
    "df_3 = reviews_df[reviews_df.Sentiment==3]\n",
    "df_2 = reviews_df[reviews_df.Sentiment==2]\n",
    "df_1 = reviews_df[reviews_df.Sentiment==1]\n",
    "\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled_5 = resample(df_5, \n",
    "                                 replace=False,\n",
    "                                 n_samples=1500,\n",
    "                                 random_state=123)\n",
    "df_majority_downsampled_4 = resample(df_4, \n",
    "                                 replace=False,\n",
    "                                 n_samples=1500,\n",
    "                                 random_state=123)\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled_5, df_majority_downsampled_4, df_3,df_2,df_1])\n",
    " \n",
    "# Display new class counts\n",
    "print(df_downsampled.Sentiment.value_counts())\n",
    "\n",
    "# Check how many rows per rating\n",
    "reviews_df=df_downsampled\n",
    "reviews_df.reset_index(inplace=True)\n",
    "reviews_df.drop(['index'], axis=1, inplace=True)\n",
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this since it has a special discount ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had a fire stick that I was having issues wi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Love Love my Fire, you get way more than you...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ok, so I will not say its perfect but it is re...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does every thing I would need it to. Nice inex...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  I bought this since it has a special discount ...          5\n",
       "1  I had a fire stick that I was having issues wi...          5\n",
       "2  I Love Love my Fire, you get way more than you...          5\n",
       "3  Ok, so I will not say its perfect but it is re...          5\n",
       "4  Does every thing I would need it to. Nice inex...          5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the df\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the samples\n",
    "reviews_df = reviews_df.sample(frac=1, random_state=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love to read! Books,books, books and more bo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did my research and purchased one of these f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality of kindle is pretty okay. Just wish ch...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased the tablet as a screen for my drin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Tap is essentially a smaller version of th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  I love to read! Books,books, books and more bo...          5\n",
       "1  I did my research and purchased one of these f...          5\n",
       "2  Quality of kindle is pretty okay. Just wish ch...          4\n",
       "3  I purchased the tablet as a screen for my drin...          3\n",
       "4  The Tap is essentially a smaller version of th...          4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the df\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love to read! Books,books, books and more bo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did my research and purchased one of these f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality of kindle is pretty okay. Just wish ch...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased the tablet as a screen for my drin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Tap is essentially a smaller version of th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Works really well only wish it had larger memo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Prob good for price but to many bugs. Freezes ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is a great tablet. This was the best one ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Whether you're a beginner or an expert, this t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I love my Echo! it is easy to use and I also u...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It gives me viewing options that I love and th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Need an alternative or supplement to Cable TV?...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The set up was easy and fast. Just plug and pl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I would purchase again. Great product for the ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>While there is absolutely nothing wrong with t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We bought this for my 86 year old cousin so sh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Haven't gotten many devices connected but my t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Purchase the echo with my Vivint system becaus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Great sound for music. Use it for a reminder e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>To much programming especially for road and tr...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Sentiment\n",
       "0   I love to read! Books,books, books and more bo...          5\n",
       "1   I did my research and purchased one of these f...          5\n",
       "2   Quality of kindle is pretty okay. Just wish ch...          4\n",
       "3   I purchased the tablet as a screen for my drin...          3\n",
       "4   The Tap is essentially a smaller version of th...          4\n",
       "5   Works really well only wish it had larger memo...          4\n",
       "6   Prob good for price but to many bugs. Freezes ...          2\n",
       "7   This is a great tablet. This was the best one ...          4\n",
       "8   Whether you're a beginner or an expert, this t...          4\n",
       "9   I love my Echo! it is easy to use and I also u...          5\n",
       "10  It gives me viewing options that I love and th...          5\n",
       "11  Need an alternative or supplement to Cable TV?...          5\n",
       "12  The set up was easy and fast. Just plug and pl...          4\n",
       "13  I would purchase again. Great product for the ...          5\n",
       "14  While there is absolutely nothing wrong with t...          4\n",
       "15  We bought this for my 86 year old cousin so sh...          5\n",
       "16  Haven't gotten many devices connected but my t...          4\n",
       "17  Purchase the echo with my Vivint system becaus...          2\n",
       "18  Great sound for music. Use it for a reminder e...          3\n",
       "19  To much programming especially for road and tr...          3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  methods for creating tokens\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text.split()\n",
    "\n",
    "def tokenizerporter(text):\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return [porter.stem(word) for word in text.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'norm', 'preprocessor', 'smooth_idf', 'stop_words', 'strip_accents', 'sublinear_tf', 'token_pattern', 'tokenizer', 'use_idf', 'vocabulary'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tfidf vectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "tfidf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into test and train models\n",
    "X_train = reviews_df.loc[:812, 'Review'].values\n",
    "y_train = reviews_df.loc[:812, 'Sentiment'].values\n",
    "X_test = reviews_df.loc[812:, 'Review'].values\n",
    "y_test = reviews_df.loc[812:, 'Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOwnloading stopwords from nltk package\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Creating list of parametrest for running the grid search against\n",
    "param_grid = [{'vect__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizerporter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__n_iter_no_change': [1,2,3,5,7,9],\n",
    "               'clf__alpha': [1e-2, 2e-2,3e-2,4e-2,5e-2,6e-2,7e-2,8e-2,9e-2,1e-1]},\n",
    "              {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizerporter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__n_iter_no_change': [1,2,3,5,7,9],\n",
    "               'clf__alpha': [1e-2, 2e-2,3e-2,4e-2,5e-2,6e-2,7e-2,8e-2,9e-2,1e-1]},\n",
    "              ]\n",
    "\n",
    "# creating pipleline for running the vectorizer and SGD classifier\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', SGDClassifier(loss='modified_huber', random_state=1))])\n",
    "# Running grid search\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9600 out of 9600 | elapsed: 27.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=False,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acc...\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x7f8d1f0f87a0>,\n",
       "                                              <function tokenizerporter at 0x7f8d1f0f8950>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting/Training the data \n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__alpha': 0.09, 'clf__n_iter_no_change': 1, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizerporter at 0x7f8d1f0f8950>} \n",
      "CV Accuracy: 0.448\n"
     ]
    }
   ],
   "source": [
    "# Print the best params and accuracy for train data\n",
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.423\n"
     ]
    }
   ],
   "source": [
    "# Print the best params and accuracy for test data\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating hashing vectorizer for streaming data\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         ngram_range=(1,1),\n",
    "                         stop_words=None,\n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "# Creating methods for streaming data\n",
    "def stream_docs(df):\n",
    "    for index, row in df.iterrows():\n",
    "        text, label = row['Review'], row['Sentiment']\n",
    "        yield text, label\n",
    "        \n",
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y\n",
    "\n",
    "# Saving the classifier\n",
    "clf = SGDClassifier(loss='modified_huber', random_state=1, penalty='l2', alpha=0.09)\n",
    "\n",
    "doc_stream = stream_docs(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the classifier using the streaming data\n",
    "classes = np.array([1, 2, 3,4,5])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=20)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.600\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation \n",
    "\n",
    "X_test, y_test = get_minibatch(doc_stream, size=20)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the test data\n",
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Saving the classifier as a pickle\n",
    "dest = os.path.join('website', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "pickle.dump(clf, open(os.path.join(dest, 'amazon_classifier_2.pkl'), 'wb'), protocol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing website/amazonreview_vectorizer.py\n"
     ]
    }
   ],
   "source": [
    "# Saving tokenizer and vectorizer in a python file to be used in the web app\n",
    "%%writefile website/amazonreview_vectorizer.py \n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "porter=PorterStemmer()\n",
    "\n",
    "cur_dir = os.path.dirname(__file__)\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text.split()\n",
    "\n",
    "def tokenizerporter(text):\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         ngram_range=(1,1),\n",
    "                         stop_words=None,\n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from amazonreview_vectorizer import vect\n",
    "\n",
    "# Loading the saved pickle to test\n",
    "model = pickle.load(open(os.path.join('pkl_objects', 'amazon_classifier_2.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.09, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=1, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n",
      "Probability: 29.46%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Testing\n",
    "label = {1:1, 2:2, 3:3,4:4,5:5}\n",
    "\n",
    "example = [\"So happy love love love\"]\n",
    "X = vect.transform(example)\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
    "      (label[model.predict(X)[0]], \n",
    "       np.max(model.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Probability: 21.55%\n"
     ]
    }
   ],
   "source": [
    "label = {1:1, 2:2, 3:3,4:4,5:5}\n",
    "# Testing\n",
    "example = [\"Won't buy again\"]\n",
    "X = vect.transform(example)\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
    "      (label[model.predict(X)[0]], \n",
    "       np.max(model.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n",
      "Probability: 22.63%\n"
     ]
    }
   ],
   "source": [
    "label = {1:1, 2:2, 3:3,4:4,5:5}\n",
    "# Testing\n",
    "\n",
    "example = [\"Bad product. never works\"]\n",
    "X = vect.transform(example)\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
    "      (label[model.predict(X)[0]], \n",
    "       np.max(model.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3\n",
      "Probability: 23.38%\n"
     ]
    }
   ],
   "source": [
    "label = {1:1, 2:2, 3:3,4:4,5:5}\n",
    "# Testing\n",
    "example = [\"not working sometimes\"]\n",
    "X = vect.transform(example)\n",
    "print('Prediction: %s\\nProbability: %.2f%%' %\\\n",
    "      (label[model.predict(X)[0]], \n",
    "       np.max(model.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQLite database with the below columns\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "conn = sqlite3.connect('reviews_2.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('DROP TABLE IF EXISTS review_db')\n",
    "c.execute('CREATE TABLE review_db (review TEXT, actual_rating INTEGER, actual_sentiment TEXT, predicted_rating INTEGER, date TEXT)')\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
